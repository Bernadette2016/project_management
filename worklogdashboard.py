# -*- coding: utf-8 -*-
"""worklogdashboard.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1bIhrVxyNZqbbv5Jp5Vj64X_FFp_2RZaC
"""

# Commented out IPython magic to ensure Python compatibility.
# %cd project_management/

import os
import re
import numpy as np
import pandas as pd
import streamlit as st
import plotly.express as px
import matplotlib.pyplot as plt
import seaborn as sns
from wordcloud import WordCloud

st.set_page_config(
    page_title="Worklog Tracker",
    page_icon="üìù",  # You can use an emoji or a local file like "favicon.png"
    layout="wide",  # Options: "wide" or "centered"
    initial_sidebar_state="expanded"  # Options: "auto", "expanded", "collapsed"
)

# Custom CSS for dark theme with background image
page_bg_img = """
<style>
[data-testid="stAppViewContainer"] {
    background-image: url("https://raw.githubusercontent.com/Bernadette2016/project_management/main/bryan-natanael-FnplrKbFEgo-unsplash.jpg");
    background-size: cover;
    background-position: center;
    background-repeat: no-repeat;
    color: #ffffff;
}

/* Darken the background with a semi-transparent overlay */
[data-testid="stAppViewContainer"]::before {
    content: "";
    position: absolute;
    top: 0;
    right: 0;
    bottom: 0;
    left: 0;
    background-color: rgba(0, 0, 0, 0.65);  /* Dark overlay */
    z-index: -1;
}

.stApp {
    background-color: transparent;
}

h1, h2, h3, h4, h5, h6, p, label {
    color: #ffffff !important;
}

.css-18e3th9 {
    background-color: rgba(30, 30, 30, 0.8) !important;
}
</style>
"""


st.markdown(page_bg_img, unsafe_allow_html=True)

st.title("Welcome to Your Worklog App")
st.write("Track your tasks, log hours, and analyze work trends easily!")

# List all filenames in your directory
file_names = ["WorkLog-export-1743799534-51e8e4143068b96803894c05ca16f93f.csv",
              "WorkLog-export-1743803562-7ad73b0a39f8fef8d1833de3dd471cee.csv",
              "WorkLog-export-1745955345-d9f9902b65ea9471787cb32422c7c087.csv",
              "WorkLog-export-1745957701-2e6df8a0f81cb1705727bb4e3813adde.csv",
              "WorkLog-export-1745957728-033ccfbde4514220201a163194a94c7e.csv",
              "WorkLog-export-1745957785-c87396d4325a3e8011592427e714453b.csv",
              "WorkLog-export-1745957824-1f5e527f5af448ae21986143d315353b.csv",
              "WorkLog-export-1745957857-d49662f3fe6cb0fe0b9c38e7cf4f05cc.csv",
              "WorkLog-export-1745958289-645b00c6bfaf295345adf4b7deaa242f.csv",
              "WorkLog-export-1745958720-725f77c29d4135bb9ea25bd87933a593.csv",
              "WorkLog-export-1745959686-29962ed776cf0fa82e8cb81f62707631.csv",
              "WorkLog-export-1745959756-dbbca352adcd8b06b17be4a483b757c3.csv",
              "WorkLog-export-1745960930-30af5c774815ac281787f0e89f1b5838.csv",
              "WorkLog-export-1745961098-4f7c09c412371417fffabf97fb6c4fe8.csv"]  # Add all file names

# Create a dictionary to store DataFrames
dfs = {}

# Loop through files and read each one into a DataFrame
for file in file_names:
    try:
        df = pd.read_csv(file)
        # Extract numeric part from filename
        match = re.search(r"\d+", file)
        file_id = int(match.group()) if match else None
        # Add "FileID" column to DataFrame
        df["FileID"] = file_id
        dfs[file] = df
    except FileNotFoundError:
        st.error(f"Error: File not found - {file}")

# Concatenate all DataFrames into one
if dfs:
    combined_df = pd.concat(dfs.values(), ignore_index=True)
    combined_df["started_at"] = pd.to_datetime(combined_df["started_at"])
    combined_df["created_at"] = pd.to_datetime(combined_df["created_at"])
    combined_df["updated_at"] = pd.to_datetime(combined_df["updated_at"])
    combined_df["user_created_at"] = pd.to_datetime(combined_df["user_created_at"])
    combined_df["user_updated_at"] = pd.to_datetime(combined_df["user_updated_at"])
else:
    st.warning("No worklog files found.")
    st.stop()

# --- Sidebar Filters ---
st.sidebar.header("Filter Your Worklogs")

# Date Range Filter
min_date = combined_df["started_at"].min().date()
max_date = combined_df["started_at"].max().date()
start_date = st.sidebar.date_input("Start Date", min_date)
end_date = st.sidebar.date_input("End Date", max_date)
filtered_df = combined_df[(combined_df["started_at"].dt.date >= start_date) & (combined_df["started_at"].dt.date <= end_date)].copy()

# Task Filter
unique_tasks = filtered_df["task"].unique()
selected_tasks = st.sidebar.multiselect("Tasks", unique_tasks)
if selected_tasks:
    filtered_df = filtered_df[filtered_df["task"].isin(selected_tasks)].copy()

# User Filter
unique_users = filtered_df["user_first_name"].unique()
selected_users = st.sidebar.multiselect("Users", unique_users)
if selected_users:
    filtered_df = filtered_df[filtered_df["user_first_name"].isin(selected_users)].copy()

# --- KPIs (moved to main content) ---
st.header("Key Performance Indicators")

# Download filtered data
csv_data = filtered_df.to_csv(index=False).encode("utf-8")
st.sidebar.download_button(
    label="üì• Download Filtered Logs",
    data=csv_data,
    file_name="filtered_worklog.csv",
    mime="text/csv"
)

col1, col2, col3 = st.columns(3)  # Create three columns for the KPIs

with col1:
    total_logged_minutes = filtered_df["minutes"].sum()
    total_logged_hours = round(total_logged_minutes / 60, 2)
    st.metric("Total Logged Hours", total_logged_hours)

with col2:
    num_log_entries = filtered_df.shape[0]
    st.metric("Number of Log Entries", num_log_entries)

with col3:
    num_unique_tasks = filtered_df["task"].nunique()
    st.metric("Unique Tasks Performed", num_unique_tasks)

# Get last 7 days of logs
st.subheader("Weekly Goal Progress")
# Weekly target input
weekly_target = st.number_input("Set Weekly Target (Hours)", min_value=1, value=40)
# Get week selection from user
filtered_df["week"] = filtered_df["started_at"].dt.isocalendar().week
week_list = sorted(filtered_df["week"].unique())
selected_week = st.selectbox("Select Week Number", week_list)
# Filter data for selected week
week_df = filtered_df[filtered_df["week"] == selected_week]
# Calculate progress
weekly_logged_minutes = week_df["minutes"].sum()
weekly_logged = round(weekly_logged_minutes / 60, 2)
progress = min(weekly_logged / weekly_target, 1.0)
# Show progress bar
st.metric("Logged Hours This Week", weekly_logged)
st.progress(progress)


st.progress(progress)
st.write(f"Logged {weekly_logged:.2f} / {weekly_target} hours this week")


st.sidebar.metric("Total Logged Hours", total_logged_hours)
st.sidebar.metric("Number of Log Entries", num_log_entries)
st.sidebar.metric("Unique Tasks Performed", num_unique_tasks)

# --- Tabbed Content ---
tab1, tab2, tab3, tab4, tab5 = st.tabs(["Raw Data", "Task Analysis", "Logged Time by Weekday", "WordCloud", "User Analysis"])

with tab1:
    st.subheader("Raw Worklog Data")
    st.dataframe(filtered_df)

with tab2:
    st.subheader("Task Analysis")
    # Time spent per task
    task_minutes = filtered_df.groupby("task")["minutes"].sum().sort_values(ascending=False)
    task_hours = round(task_minutes / 60, 2)
    st.subheader("Total Time Spent per Task (Hours)")
    st.bar_chart(task_hours)
    # Daily time spent trend
    filtered_df["day"] = filtered_df["started_at"].dt.date
    daily_hours = filtered_df.groupby("day")["minutes"].sum() / 60
    st.subheader("Daily Time Spent (Hours)")
    st.line_chart(daily_hours)

    # Activity heatmap
    filtered_df["weekday"] = filtered_df["started_at"].dt.day_name()
    filtered_df["hour"] = filtered_df["started_at"].dt.hour
    heatmap_data = filtered_df.pivot_table(
    index="weekday", columns="hour", values="minutes", aggfunc="sum", fill_value=0
    )

with tab3:
    st.subheader("Logged Time by Weekday")
    # --- User Filter ---
    user_options = combined_df["user_first_name"].dropna().unique()
    selected_user = st.selectbox("Select a User", options=sorted(user_options))
    # Filter the data by selected user
    user_df = combined_df[combined_df["user_first_name"] == selected_user].copy()
    # Step 1: Prepare data
    user_df["weekday"] = user_df["started_at"].dt.day_name()
    weekday_minutes = user_df.groupby("weekday")["minutes"].sum()
    # Step 2: Reorder weekdays
    ordered_days = ["Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday", "Sunday"]
    weekday_minutes = weekday_minutes.reindex(ordered_days).fillna(0)
    # Step 3: Convert to hours and round
    weekday_hours = (weekday_minutes / 60).round(2)
    # Step 4: Plot bar chart
    st.bar_chart(weekday_hours)

with tab4:
    # Word Cloud of Task Descriptions
    text = " ".join(filtered_df["description"].astype(str))
    wordcloud = WordCloud(width=800, height=400, background_color="white").generate(text)
    st.subheader("Word Cloud of Task Descriptions")
    fig, ax = plt.subplots(figsize=(10, 5))  # Create a Matplotlib figure and axes
    ax.imshow(wordcloud, interpolation="bilinear")
    ax.axis("off")
    st.pyplot(fig)  # Pass the figure object to st.pyplot()

with tab5:
    st.subheader("User Analysis")
    # Time spent per user
    user_minutes = filtered_df.groupby("user_first_name")["minutes"].sum().sort_values(ascending=False)
    user_hours = round(user_minutes / 60, 2)
    st.subheader("Total Time Spent per User (Hours)")
    st.bar_chart(user_hours)

    # Average feedback per user
    avg_feedback = filtered_df.groupby("user_first_name")["user_feedbacks_average"].mean().sort_values(ascending=False)
    st.subheader("Average User Feedback")
    st.bar_chart(avg_feedback)
    st.subheader("User Drilldown")
    selected_user = st.selectbox("Select a User to View Their Logs", options=filtered_df["user_first_name"].unique())
    user_df = filtered_df[filtered_df["user_first_name"] == selected_user]
    
    st.write(f"Total entries for {selected_user}: {user_df.shape[0]}")
    st.dataframe(user_df[["started_at", "task", "minutes", "description"]])
